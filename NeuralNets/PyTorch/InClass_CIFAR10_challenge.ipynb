{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import torch\n",
    "import imageio\n",
    "import torchvision\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## !pip install torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.cuda.device_count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.cuda.current_device()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA A30'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.cuda.get_device_name(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## CIFAR10 DATA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "raw_data_train = '/home/rcalix/Desktop/CIFAR-10-images-master/train/'\n",
    "\n",
    "raw_data_test  = '/home/rcalix/Desktop/CIFAR-10-images-master/test/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Train data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_train = []\n",
    "labels_train  = []\n",
    "targets_train = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for folder in os.listdir( raw_data_train ):\n",
    "    ## print(folder)\n",
    "    for image in os.listdir( os.path.join(raw_data_train, folder) ):\n",
    "        if folder not in labels_train:\n",
    "            labels_train.append( folder )\n",
    "        targets_train.append(  labels_train.index(folder)  )\n",
    "        img_arr = imageio.imread(  os.path.join(raw_data_train, folder, image), pilmode=\"RGB\"  )\n",
    "        \n",
    "        img = torch.from_numpy( img_arr ).permute( 2, 0, 1 ).float()\n",
    "        \n",
    "        img /= 255\n",
    "        dataset_train.append(img)\n",
    "        \n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(labels_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len( targets_train )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset_train[3].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_train    = torch.stack( dataset_train )\n",
    "targets_train = torch.Tensor(  targets_train  ).type(   torch.LongTensor   )\n",
    "\n",
    "torch.save(   (data_train, targets_train, labels_train), \"InClass_CIFAR10_data\"     )\n",
    "\n",
    "## data1, targets1, labels1 = torch.load(\"InClass_CIFAR10_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 3, 32, 32])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "targets_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_train[4].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "targets_train[24000:25000]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Print images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000, 0.0000,  ..., 0.0157, 0.0196, 0.0157],\n",
       "         [0.0000, 0.0039, 0.0078,  ..., 0.0196, 0.0039, 0.0039],\n",
       "         [0.0157, 0.0039, 0.0000,  ..., 0.0078, 0.0039, 0.0196],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0275, 0.0314, 0.0314],\n",
       "         [0.0353, 0.0275, 0.0000,  ..., 0.0118, 0.0157, 0.0157],\n",
       "         [0.0000, 0.0235, 0.0000,  ..., 0.0157, 0.0235, 0.0275]],\n",
       "\n",
       "        [[0.0078, 0.0078, 0.0118,  ..., 0.0000, 0.0039, 0.0000],\n",
       "         [0.0118, 0.0157, 0.0157,  ..., 0.0118, 0.0000, 0.0000],\n",
       "         [0.0157, 0.0039, 0.0000,  ..., 0.0078, 0.0039, 0.0196],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0196, 0.0118, 0.0157],\n",
       "         [0.0353, 0.0275, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0235, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.0000, 0.0000, 0.0000,  ..., 0.0039, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0157, 0.0000, 0.0000],\n",
       "         [0.0078, 0.0000, 0.0000,  ..., 0.0078, 0.0039, 0.0196],\n",
       "         ...,\n",
       "         [0.0078, 0.0078, 0.0078,  ..., 0.0235, 0.0275, 0.0196],\n",
       "         [0.0353, 0.0275, 0.0078,  ..., 0.0078, 0.0157, 0.0078],\n",
       "         [0.0000, 0.0235, 0.0078,  ..., 0.0196, 0.0235, 0.0275]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "img_tr = data_train[46000]\n",
    "img_tr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform = T.ToPILImage()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img = transform(  img_tr  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDw46c4hWYv+6bo/ltt/PFN+wZUkTof+At/hXb+CWvLpJbHy/MghG8sTxGp4I9wSenNdePDmjWsyNcR2iPcFki87EZfBxnGB/Tis5VFF2aLjDmV0eL/AGRMZ+0x8dflb/Cp/wCyZfIE+7ELHAkMb7SfQHFe06v4d8N2s6eTBbGYQglZrc7VYHrtAzjvz2rz/Wn1C/gkmNvM1vCxjaSNCyKRzj2GMYpOo72SHyK17nonwp0q1v8AwTqsTloZ7i5EfmgcgBMjH5mt6y1a1sLyRLuANawcLC6B92OO/T614hofxA1fw/aTWtjDaeVK4kKyKzYYDAI+b3p9x8R9ZupDJLb2JYnJIjYf+zVco3dyYysrHpd9q9zqc9zcXcj+a52r8oX5M8A461yrG6s7u58udkhmxvVWIB+ormP+E91T/n3s/psb/wCKqGTxlfynL29oT/uN/jStIJNN6H//2Q==\n",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAI0ElEQVR4AWVWW28bxxWe2Z29cMkltRYlUpJl2rIkykqs2rELx26cpGmBIugFbdGXAjXQn9GnvvXP9KlAi8YoivTiFDYK23KtyI4lWbFEUZR4X3Lvl9l+Q7lFgQ6o9XjmzDnfuR9KJCIWJSSbbP77kQnh/3dIiIKzTPywcE8p3uExTjJZlmlGUp6CJcUNxRk2siAS/CVxxnn2lu//iMQWNBz8CJEFt7dLSBKPKJFolkJGigvcq4rKOU/SBP+VGJVISnhCspjwKCMJKCRJkt+KAVKBQhKIQC4A4iNRiREq80zKMsozmlHZyJvghh+uMiqlGccLpihgL+MJHoOVwIK/TBInQCdOBUSZglHGM4FIcMGJLIuTVEAWmGWZYA9eVAL2DMrSib6EMF3RJQVflTLxJk6SNE4hX5EBRDzHAsOJyimWzCbswRHSQSi8kUHlIPAKpqEoShiGYMAUgQl7trpaF6CzLIrCOI6x1zRN13U8PMOAx0SaCEggPGUMRs1AJpbQD6I5rG/ktITHnudFUYTnZsmUJRZGAc0xI4el6SmPXdfFNVioqjoBDpOBTIYAaCPwpyl8x7OUIlQkaA6j4yCK4yinKTGPoYGRz+Ot5ztxmmmawqIkmLeqa/UVyyq5o3Hj6ODkuDUej/Ogg03hbpVJTAFmYTjOvdGYx5CRwH2qrEAubCrB72k8P2O9d+Na/cpap9N5+OjR8fFxvqAx0ISpv7a+Iku0w/jS0u1qZeb+/fsnJy2osrvbLJhqoViCH2rnL/T7fRpSq1JJo7DXbeuURHEQ+KRSZh99dPfu3W91u93d17uNZssq6B3YNXSppsO3/M7tWzevX2Mke/Xiy8WFufK0BTU7nXYYxScnJ1rOvHCxNnLcOIwWqouqRJkkvdh+jtCetopJFN56/5v9fvfw8MD1PT+MDo8aSZrZjuu4HjOtkuc4f/37I54EP/z0eyurl3iEiLBf7+0YhrGyuloqKAmXlmpVIjNdy5FU0hS1fdwqFY3z1dn6yqXAc5MkIkk06LTzZmHk+0kUA40bRAhDShhZuDA/HvTnZqdvXt9QaTpjFXVGaxcWHXvYt0eWZZnFEoQhg7Zf7hZL5R//6Cfu2N55uW0POjwKXcd+8OBviCmExrnyzObWlpbLj1yv2Rrl8nBUoTSwvZEduF709f5Br9tHICGXdIWlSWTm9LymDjqnb/b2xsPBfHV24/q10nR58dJFwzTDlEMppuv1K+tRkvZHzmHzpDsYx6mcL05XFmb1whRDuhNZmZmbY6rcbLVmrXqpUKotVleX6wev9+orq7m8USnPFK2pxmHTKE0vXV55svW8trAwGDuqkV+rL+/tvrq6cS3m9IuHj7gTTlfmD5otP+bVufnByGEzlUXXHY+coetEH9y8fu8X94bto+7p0V+OPu91+ovfPo/02nz6r1y7g/RYWV7+wx8/c6IECdXq9Y4O3mA1GwdWqZikBK7ywvD2zTvM+Hpn/8BLpK7tMdseKTIplaY0OavVLlUq1dPGft60Fqrl5eVl+LVx9OazP/252WytvbP+8k3rkx/8jKi5h/94cNRoJH6kKvp773/w7MlTiJyeW4xO27fufPjTn//y2fOtrS9fSMomQ6orqsrj8EKtdu/evVG/bZam3+y9QkRf29gYOEFtef1Xv/7NV692kF6yanx452PX82PHH3aG1lwNUpvNRmHmvOz7w7ilmunnXzz6rl549+o3FEWUHJbTVYrSpqrvXFm/VLt4ItPG/t7O3uuVy0tUVlw/9sJudX7hO59+v1pZQPYjGBx7ZKjGfHVuaI+3t1/07FFKZUkxmKb5UbL1Yhu5MF22Qj/yfZeJophlhXz+xo0b5XLZGw1kJtrFxsaGnjN6vR6CCrnTHdpM1s4vLf/+t7/b3Nwcu66iwzx6ksQoFooiw1V5I1cqFhxn3B90o9hXZEXTVIb6pcgSwvzy5csQhmqFTZp8Mlud63XaKEroHlyKmRf27WHFRTL7h2/2vTBYrddnZs6hPkVRgAT23DHyM00j9E1VFd2TZ3EUc9TDDJ0UYmAvFAbUtZW1tYX56t7OV6edbqfXTzO6Wp9dv3oVpenp06cje1DI6aglAIsiEUQhCh9jkmnm0SVVDSXaj5OQJai2KMToKlkG7YbDoW3b6A9YRjFPC0V0jXa37/qhphvD8fjVzk6vN0CFaB0cjAZ9Qs51To9lTZM0BhOpCjqlbJ0rcjJv20OKPgncMjMMjQG9omowjuM4YZJ2egO0deQw0w0UrJxRQMbCUP2BPRo5KpPNQl7Fc5kFvmsoeC4FvkdVCY6VFIkxGX0NLQ56RGHkuAmOmDVVKltT2ECMPRoj6SUZfcO0ZmYMFJLhqNcfajlDQc0YDPRcDrFQKpmgRyODxvABqtDUVBH+Q/UWlUYmomVRHgSBhM4N7Dg9PDwsFBADzj+fPGu02mjbZmkqjBO0M/xQ4seunzeLfhi6AY45lDsbIIpTFk/R72BsOilduQAB6oXohgrTGCIScnCw//XBYaNpmMVcwQzCSPQyJacXTMIUiOfEg6ugImJPImjCaJuEi4EKUmS01oRzlhFNQ+uTVFVD1IAG9OzdK2uotAAOPz9+/FhEraK0T1vQ0XfGsACIcIhOjJEMnVE0eDRixCDmGDGwSJTDERQewrADuIKOi2lIjDPoB8CJFQYBlSSkBe7RjWFrcScICEIQLRfdHtOFqjASJ2cDx2QkElOSEIPBA9d4MhnPMFOdLWE1XGL+mjBCYPjYoGzEUQRazD14JoYTYRLxBNF4hlvMipj2oAouRSlAWAqCs+8ZMiEQ+PCXxDG+ZxBkxs5sLbBQccvhwf8gAvi3W7AHbyJ0E1Mt4ZKiiZlQiBUmwwlMh0BiGIlgFkxjE46SZuS98RhhPhn/BD+KHBLSxUtYHVOhgCuGL/w7QSnGZo5ZBkzTM9agFxEwEez7/hksuEFoMwkV1FlhIgylwlCwklBauBq3wAnvQE4qPAMFhF0oQhkwMBGDFJkqvmIgJMq/AbOkLUyuPzySAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Class balance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_train_np = targets_train.numpy() \n",
    "y_train_np.shape\n",
    "\n",
    "the_set = np.unique(  y_train_np  )\n",
    "the_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "_ = plt.hist( targets_train.numpy() , bins=\"auto\" )\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Test Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_test = []\n",
    "labels_test = []\n",
    "targets_test = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for folder in os.listdir( raw_data_test ):\n",
    "    ## print(folder)\n",
    "    for image in os.listdir( os.path.join(raw_data_test, folder) ):\n",
    "        if folder not in labels_test:\n",
    "            labels_test.append( folder )\n",
    "        targets_test.append(  labels_test.index(folder)  )\n",
    "        img_arr = imageio.imread(  os.path.join(raw_data_test, folder, image), pilmode=\"RGB\"  )\n",
    "        \n",
    "        img = torch.from_numpy( img_arr ).permute( 2, 0, 1 ).float()\n",
    "        \n",
    "        img /= 255\n",
    "        dataset_test.append(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_test   = torch.stack( dataset_test )\n",
    "targets_test = torch.Tensor(  targets_test  ).type(   torch.LongTensor   )\n",
    "\n",
    "torch.save(   (data_test, targets_test, labels_test), \"InClass_CIFAR10_data_test\"     )\n",
    "\n",
    "## data1, targets1, labels1 = torch.load(\"InClass_CIFAR10_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 3, 32, 32])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "targets_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAOG0lEQVR4nO3cX4idd53H8fdnE+1fiimdlpikmwihmhak7pCtFmTZCM2uYnphYYR2g3QJLFGrCJJ406tAL0R0YVsIrW4WS0OIhQZ317VEZVnYbXf6B9okhg6Nm4wZm3EXtXiRNvW7F+eRnE4nbeac6Zx0fu8XhPOc33me+f3yMHmfk2fmnFQVkqQ2/MmoFyBJWjpGX5IaYvQlqSFGX5IaYvQlqSErR72Ad3LdddfV+vXrR70MSXpPeeaZZ35dVWNzxy/56K9fv57JyclRL0OS3lOS/M98417ekaSGGH1JaojRl6SGGH1JaojRl6SGGH1Jasg7Rj/Jd5OcSfJi39i1SZ5M8lJ3u6rvsd1JppIcT3JH3/ifJXmhe+zvk2Tx/zqSpLdzMa/0/xHYOmdsF3C4qjYCh7v7JNkETAA3d8c8mGRFd8xDwA5gY/dn7teUJL3L3jH6VfXvwP/NGd4G7Ou29wF39o3vr6qzVXUCmAI2J1kNXFNV/1m9D/D/p75jJElLZNB35N5QVTMAVTWT5PpufA3wX337TXdjr3fbc8fnlWQHvf8VcOONNw64RFi/658HPvYXD3x6JPOOcu734ryjnntQfo8s3byjnPtS/N5c7B/kznedvt5mfF5VtbeqxqtqfGzsLR8dIUka0KDRf6W7ZEN3e6YbnwbW9e23Fjjdja+dZ1yStIQGjf4hYHu3vR14om98IsllSTbQ+4Ht092loFeT3Nb91s7f9B0jSVoi73hNP8ljwF8A1yWZBu4HHgAOJLkXOAncBVBVR5IcAI4C54CdVfVG96X+jt5vAl0B/Gv3R5K0hN4x+lX1+Qs8tOUC++8B9swzPgncsqDVSZIWle/IlaSGGH1JaojRl6SGGH1JaojRl6SGGH1JaojRl6SGGH1JaojRl6SGGH1JaojRl6SGGH1JaojRl6SGGH1JaojRl6SGGH1JaojRl6SGGH1JaojRl6SGGH1JaojRl6SGGH1JaojRl6SGGH1JaojRl6SGGH1JaojRl6SGGH1JaojRl6SGGH1JaojRl6SGGH1JashQ0U/y1SRHkryY5LEklye5NsmTSV7qblf17b87yVSS40nuGH75kqSFGDj6SdYAXwbGq+oWYAUwAewCDlfVRuBwd58km7rHbwa2Ag8mWTHc8iVJCzHs5Z2VwBVJVgJXAqeBbcC+7vF9wJ3d9jZgf1WdraoTwBSwecj5JUkLMHD0q+qXwDeBk8AM8Nuq+jFwQ1XNdPvMANd3h6wBTvV9ielu7C2S7EgymWRydnZ20CVKkuYY5vLOKnqv3jcAHwSuSnL32x0yz1jNt2NV7a2q8aoaHxsbG3SJkqQ5hrm88yngRFXNVtXrwOPAJ4BXkqwG6G7PdPtPA+v6jl9L73KQJGmJDBP9k8BtSa5MEmALcAw4BGzv9tkOPNFtHwImklyWZAOwEXh6iPklSQu0ctADq+qpJAeBZ4FzwHPAXuBq4ECSe+k9MdzV7X8kyQHgaLf/zqp6Y8j1S5IWYODoA1TV/cD9c4bP0nvVP9/+e4A9w8wpSRqc78iVpIYYfUlqiNGXpIYYfUlqiNGXpIYYfUlqiNGXpIYYfUlqiNGXpIYYfUlqiNGXpIYYfUlqiNGXpIYYfUlqiNGXpIYYfUlqiNGXpIYYfUlqiNGXpIYYfUlqiNGXpIYYfUlqiNGXpIYYfUlqiNGXpIYYfUlqiNGXpIYYfUlqiNGXpIYYfUlqiNGXpIYYfUlqyFDRT/KBJAeT/DzJsSQfT3JtkieTvNTdrurbf3eSqSTHk9wx/PIlSQsx7Cv97wA/qqoPAx8FjgG7gMNVtRE43N0nySZgArgZ2Ao8mGTFkPNLkhZg4OgnuQb4JPAIQFW9VlW/AbYB+7rd9gF3dtvbgP1VdbaqTgBTwOZB55ckLdwwr/Q/BMwC30vyXJKHk1wF3FBVMwDd7fXd/muAU33HT3djkqQlMkz0VwIfAx6qqluB39NdyrmAzDNW8+6Y7EgymWRydnZ2iCVKkvoNE/1pYLqqnuruH6T3JPBKktUA3e2Zvv3X9R2/Fjg93xeuqr1VNV5V42NjY0MsUZLUb+DoV9WvgFNJbuqGtgBHgUPA9m5sO/BEt30ImEhyWZINwEbg6UHnlyQt3Mohj/8S8GiS9wMvA1+g90RyIMm9wEngLoCqOpLkAL0nhnPAzqp6Y8j5JUkLMFT0q+p5YHyeh7ZcYP89wJ5h5pQkDc535EpSQ4y+JDXE6EtSQ4y+JDXE6EtSQ4y+JDXE6EtSQ4y+JDXE6EtSQ4y+JDXE6EtSQ4y+JDXE6EtSQ4y+JDXE6EtSQ4y+JDXE6EtSQ4y+JDXE6EtSQ4y+JDXE6EtSQ4y+JDXE6EtSQ4y+JDXE6EtSQ4y+JDXE6EtSQ4y+JDXE6EtSQ4y+JDXE6EtSQ4y+JDXE6EtSQ4aOfpIVSZ5L8sPu/rVJnkzyUne7qm/f3UmmkhxPcsewc0uSFmYxXunfBxzru78LOFxVG4HD3X2SbAImgJuBrcCDSVYswvySpIs0VPSTrAU+DTzcN7wN2Ndt7wPu7BvfX1Vnq+oEMAVsHmZ+SdLCDPtK/9vA14E/9I3dUFUzAN3t9d34GuBU337T3dhbJNmRZDLJ5Ozs7JBLlCT90cDRT/IZ4ExVPXOxh8wzVvPtWFV7q2q8qsbHxsYGXaIkaY6VQxx7O/DZJH8NXA5ck+T7wCtJVlfVTJLVwJlu/2lgXd/xa4HTQ8wvSVqggV/pV9XuqlpbVevp/YD2J1V1N3AI2N7tth14ots+BEwkuSzJBmAj8PTAK5ckLdgwr/Qv5AHgQJJ7gZPAXQBVdSTJAeAocA7YWVVvvAvzS5IuYFGiX1U/A37Wbf8vsOUC++0B9izGnJKkhfMduZLUEKMvSQ0x+pLUEKMvSQ0x+pLUEKMvSQ0x+pLUEKMvSQ0x+pLUEKMvSQ0x+pLUEKMvSQ0x+pLUEKMvSQ0x+pLUEKMvSQ0x+pLUEKMvSQ0x+pLUEKMvSQ0x+pLUEKMvSQ0x+pLUEKMvSQ0x+pLUEKMvSQ0x+pLUEKMvSQ0x+pLUEKMvSQ0x+pLUEKMvSQ0ZOPpJ1iX5aZJjSY4kua8bvzbJk0le6m5X9R2zO8lUkuNJ7liMv4Ak6eIN80r/HPC1qvoIcBuwM8kmYBdwuKo2Aoe7+3SPTQA3A1uBB5OsGGbxkqSFGTj6VTVTVc92268Cx4A1wDZgX7fbPuDObnsbsL+qzlbVCWAK2Dzo/JKkhVuUa/pJ1gO3Ak8BN1TVDPSeGIDru93WAKf6Dpvuxub7ejuSTCaZnJ2dXYwlSpJYhOgnuRr4AfCVqvrd2+06z1jNt2NV7a2q8aoaHxsbG3aJkqTOUNFP8j56wX+0qh7vhl9Jsrp7fDVwphufBtb1Hb4WOD3M/JKkhRnmt3cCPAIcq6pv9T10CNjebW8Hnugbn0hyWZINwEbg6UHnlyQt3Mohjr0duAd4Icnz3dg3gAeAA0nuBU4CdwFU1ZEkB4Cj9H7zZ2dVvTHE/JKkBRo4+lX1H8x/nR5gywWO2QPsGXROSdJwfEeuJDXE6EtSQ4y+JDXE6EtSQ4y+JDXE6EtSQ4y+JDXE6EtSQ4y+JDXE6EtSQ4y+JDXE6EtSQ4y+JDXE6EtSQ4y+JDXE6EtSQ4y+JDXE6EtSQ4y+JDXE6EtSQ4y+JDXE6EtSQ4y+JDXE6EtSQ4y+JDXE6EtSQ4y+JDXE6EtSQ4y+JDXE6EtSQ4y+JDXE6EtSQ4y+JDVkyaOfZGuS40mmkuxa6vklqWVLGv0kK4B/AP4K2AR8PsmmpVyDJLVsqV/pbwamqurlqnoN2A9sW+I1SFKzUlVLN1nyOWBrVf1td/8e4M+r6otz9tsB7Oju3gQcH3DK64BfD3jscuT5OM9z8Waej/OWy7n406oamzu4cokXkXnG3vKsU1V7gb1DT5ZMVtX4sF9nufB8nOe5eDPPx3nL/Vws9eWdaWBd3/21wOklXoMkNWupo//fwMYkG5K8H5gADi3xGiSpWUt6eaeqziX5IvBvwArgu1V15F2ccuhLRMuM5+M8z8WbeT7OW9bnYkl/kCtJGi3fkStJDTH6ktSQZRl9P+rhvCTrkvw0ybEkR5LcN+o1jVqSFUmeS/LDUa9l1JJ8IMnBJD/vvkc+Puo1jVKSr3b/Tl5M8liSy0e9psW27KLvRz28xTnga1X1EeA2YGfj5wPgPuDYqBdxifgO8KOq+jDwURo+L0nWAF8GxqvqFnq/bDIx2lUtvmUXffyohzepqpmqerbbfpXeP+o1o13V6CRZC3waeHjUaxm1JNcAnwQeAaiq16rqNyNd1OitBK5IshK4kmX4PqLlGP01wKm++9M0HLl+SdYDtwJPjXgpo/Rt4OvAH0a8jkvBh4BZ4Hvd5a6Hk1w16kWNSlX9EvgmcBKYAX5bVT8e7aoW33KM/kV91ENrklwN/AD4SlX9btTrGYUknwHOVNUzo17LJWIl8DHgoaq6Ffg90OzPwJKsondVYAPwQeCqJHePdlWLbzlG3496mCPJ++gF/9GqenzU6xmh24HPJvkFvct+f5nk+6Nd0khNA9NV9cf/+R2k9yTQqk8BJ6pqtqpeBx4HPjHiNS265Rh9P+qhT5LQu2Z7rKq+Ner1jFJV7a6qtVW1nt73xU+qatm9krtYVfUr4FSSm7qhLcDRES5p1E4CtyW5svt3s4Vl+IPtpf6UzXfdCD7q4VJ3O3AP8EKS57uxb1TVv4xuSbqEfAl4tHuB9DLwhRGvZ2Sq6qkkB4Fn6f3W23Msw49k8GMYJKkhy/HyjiTpAoy+JDXE6EtSQ4y+JDXE6EtSQ4y+JDXE6EtSQ/4fp8mINnfOoV4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "_ = plt.hist( targets_test.numpy() , bins=\"auto\" )\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = data_train  \n",
    "y_train = targets_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_test = data_test  \n",
    "y_test = targets_test \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_train[30000].item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4510, 0.4471, 0.4510,  ..., 0.2549, 0.3373, 0.3529],\n",
       "         [0.4863, 0.4980, 0.5020,  ..., 0.2863, 0.3647, 0.3608],\n",
       "         [0.4431, 0.4667, 0.4706,  ..., 0.3098, 0.3608, 0.3255],\n",
       "         ...,\n",
       "         [0.4510, 0.4588, 0.4549,  ..., 0.4706, 0.4510, 0.4353],\n",
       "         [0.4392, 0.4549, 0.4510,  ..., 0.4667, 0.4549, 0.4431],\n",
       "         [0.4157, 0.4471, 0.4510,  ..., 0.4431, 0.4392, 0.4353]],\n",
       "\n",
       "        [[0.5294, 0.5255, 0.5137,  ..., 0.2980, 0.3843, 0.4039],\n",
       "         [0.5569, 0.5725, 0.5647,  ..., 0.3294, 0.4118, 0.4118],\n",
       "         [0.5059, 0.5294, 0.5333,  ..., 0.3529, 0.4039, 0.3765],\n",
       "         ...,\n",
       "         [0.4627, 0.4784, 0.4745,  ..., 0.4824, 0.4784, 0.4627],\n",
       "         [0.4588, 0.4745, 0.4706,  ..., 0.4784, 0.4784, 0.4784],\n",
       "         [0.4353, 0.4667, 0.4824,  ..., 0.4667, 0.4627, 0.4667]],\n",
       "\n",
       "        [[0.5255, 0.5216, 0.5098,  ..., 0.2314, 0.3059, 0.3255],\n",
       "         [0.5569, 0.5647, 0.5608,  ..., 0.2627, 0.3333, 0.3333],\n",
       "         [0.5020, 0.5255, 0.5294,  ..., 0.2863, 0.3373, 0.3059],\n",
       "         ...,\n",
       "         [0.3804, 0.3922, 0.3961,  ..., 0.4392, 0.4157, 0.3922],\n",
       "         [0.3725, 0.3882, 0.3922,  ..., 0.4353, 0.4235, 0.4118],\n",
       "         [0.3490, 0.3804, 0.4000,  ..., 0.4196, 0.4157, 0.4078]]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    " X_train[78]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " CIFAR_train_list = [  ( X_train[i],  y_train[i].item() )  for i in range( X_train.shape[0]   )  ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " CIFAR_test_list = [  ( X_test[i],  y_test[i].item() )  for i in range( X_test.shape[0]   )  ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dl = torch.utils.data.DataLoader( CIFAR_train_list, batch_size=batch_size, shuffle=True  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_dl = torch.utils.data.DataLoader( CIFAR_test_list, batch_size=10000, shuffle=True  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Architectures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3072"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "32*32*3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MLP_net(nn.Module):\n",
    "    ## init the class\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear( 32*32*3 ,20)\n",
    "        self.act1    = nn.Sigmoid()\n",
    "        self.linear2 = nn.Linear(20 , 10)\n",
    "        self.act2    = nn.Softmax(dim=1)\n",
    "        \n",
    "    ## perform inference\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x            = self.linear1(x)\n",
    "        x            = self.act1(x)\n",
    "        x            = self.linear2(x)\n",
    "        y_pred       = self.act2(x)\n",
    "        \n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def training_loop( N_Epochs, model, loss_fn, opt ):\n",
    "    for epoch in range(N_Epochs):\n",
    "        for xb, yb in train_dl:\n",
    "            \n",
    "            xb = xb.view(  (16, -1 ) )\n",
    "            \n",
    "            y_pred = model(xb)\n",
    "            \n",
    "            loss = loss_fn(y_pred, yb)\n",
    "            \n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        \n",
    "        if epoch % 5 == 0:\n",
    "            print(epoch, \"loss=\", loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Core functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N_Epochs      = 100\n",
    "learning_rate = 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = MLP_net()\n",
    "\n",
    "opt = torch.optim.Adam(  model.parameters(), lr=learning_rate  )\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss= tensor(2.2100, grad_fn=<NllLossBackward0>)\n",
      "5 loss= tensor(2.1529, grad_fn=<NllLossBackward0>)\n",
      "10 loss= tensor(1.9594, grad_fn=<NllLossBackward0>)\n",
      "15 loss= tensor(2.1587, grad_fn=<NllLossBackward0>)\n",
      "20 loss= tensor(2.1462, grad_fn=<NllLossBackward0>)\n",
      "25 loss= tensor(1.9320, grad_fn=<NllLossBackward0>)\n",
      "30 loss= tensor(1.9844, grad_fn=<NllLossBackward0>)\n",
      "35 loss= tensor(2.0333, grad_fn=<NllLossBackward0>)\n",
      "40 loss= tensor(1.9106, grad_fn=<NllLossBackward0>)\n",
      "45 loss= tensor(1.9092, grad_fn=<NllLossBackward0>)\n",
      "50 loss= tensor(2.0887, grad_fn=<NllLossBackward0>)\n",
      "55 loss= tensor(2.2024, grad_fn=<NllLossBackward0>)\n",
      "60 loss= tensor(1.9450, grad_fn=<NllLossBackward0>)\n",
      "65 loss= tensor(1.9127, grad_fn=<NllLossBackward0>)\n",
      "70 loss= tensor(2.1491, grad_fn=<NllLossBackward0>)\n",
      "75 loss= tensor(1.9169, grad_fn=<NllLossBackward0>)\n",
      "80 loss= tensor(1.9179, grad_fn=<NllLossBackward0>)\n",
      "85 loss= tensor(1.9163, grad_fn=<NllLossBackward0>)\n",
      "90 loss= tensor(2.1334, grad_fn=<NllLossBackward0>)\n",
      "95 loss= tensor(1.8568, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "training_loop( N_Epochs, model, loss_fn, opt )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_metrics_function(y_test, y_pred):\n",
    "    print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))\n",
    "    confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confmat)\n",
    "    print('Precision: %.3f' % precision_score(y_true=y_test, y_pred=y_pred, average='weighted'))\n",
    "    print('Recall: %.3f' % recall_score(y_true=y_test, y_pred=y_pred, average='weighted'))\n",
    "    print('F1-measure: %.3f' % f1_score(y_true=y_test, y_pred=y_pred, average='weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.14\n",
      "Confusion Matrix:\n",
      "[[259  62   9  35  43  13 144  76  59 300]\n",
      " [ 32  15  43 136 563  60  18  14   3 116]\n",
      " [ 33  28  19 539  62 103  53  17  15 131]\n",
      " [ 53 413  23  35  25  57  80  39  87 188]\n",
      " [ 42  95  34  17  32  15 201  75 302 187]\n",
      " [ 11  53  22 228  88 378  67   6   3 144]\n",
      " [ 62  61  80  38  65  10 188 149 130 217]\n",
      " [ 50  23   4  27  17   8 543  28  84 216]\n",
      " [ 14  57 316  69 235  50  38  39  15 167]\n",
      " [142  43  18  44  31  31 178  50  29 434]]\n",
      "Precision: 0.141\n",
      "Recall: 0.140\n",
      "F1-measure: 0.133\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    for x_real, y_real in test_dl:\n",
    "        \n",
    "        batch_size = x_real.shape[0]\n",
    "        \n",
    "        x_real = x_real.view(  (batch_size, -1 ) )\n",
    "        \n",
    "        y_pred = model(  x_real  )\n",
    "        \n",
    "        vals, indeces = torch.max( y_pred, dim=1  )\n",
    "        preds = indeces\n",
    "        print_metrics_function(y_real, preds)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3072])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rc = data_train[4].view((-1))\n",
    "rc.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3072])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rc = torch.unsqueeze(rc, dim=0)\n",
    "rc.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "example_label = model( rc )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1068, 0.1435, 0.1445, 0.0660, 0.1300, 0.0566, 0.0941, 0.1157, 0.0780,\n",
       "         0.0648]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "example_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (Anaconda 2020.11)",
   "language": "python",
   "name": "anaconda-2020.11-py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
