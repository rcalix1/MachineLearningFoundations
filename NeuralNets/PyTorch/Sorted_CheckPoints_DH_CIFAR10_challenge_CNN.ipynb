{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import torch\n",
    "import imageio\n",
    "import torchvision\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torcheval.metrics.functional import multiclass_f1_score as f1_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## CNNs for CIFAR10\n",
    "\n",
    "* https://rcalix1.github.io/DeepLearningAlgorithms/SecondEdition/chapter6_CNNs/index.html\n",
    "\n",
    "## Load and save torch model checkpoints\n",
    "\n",
    "* https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "\n",
    "## Data\n",
    "\n",
    "* Data: https://github.com/YoongiKim/CIFAR-10-images/tree/master\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## !pip install torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.cuda.device_count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.cuda.current_device()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla V100-PCIE-32GB'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.cuda.get_device_name(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Assign device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch_device = torch.device(\"cpu\")\n",
    "\n",
    "if torch.cuda.is_available(): \n",
    "    torch_device = torch.device(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch_device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## CIFAR10 DATA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "raw_data_train = '/scratch/scholar/rcalix/CIFAR-10-images-master/train/'\n",
    "\n",
    "raw_data_test  = '/scratch/scholar/rcalix/CIFAR-10-images-master/test/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## PATH to checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PATH = \"/scratch/scholar/rcalix/CNN_model_CIFAR10\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Train data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_train = []\n",
    "labels_train  = []\n",
    "targets_train = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_132106/356766511.py:7: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  img_arr = imageio.imread(  os.path.join(raw_data_train, folder, image), pilmode=\"RGB\"  )\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for folder in sorted( os.listdir( raw_data_train ) ):\n",
    "    ## print(folder)\n",
    "    for image in sorted(os.listdir( os.path.join(raw_data_train, folder) )):\n",
    "        if folder not in labels_train:\n",
    "            labels_train.append( folder )\n",
    "        targets_train.append(  labels_train.index(folder)  )\n",
    "        img_arr = imageio.imread(  os.path.join(raw_data_train, folder, image), pilmode=\"RGB\"  )\n",
    "        \n",
    "        img = torch.from_numpy( img_arr ).permute( 2, 0, 1 ).float()\n",
    "        \n",
    "        img /= 255\n",
    "        dataset_train.append(img)\n",
    "        \n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(labels_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len( targets_train )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset_train[3].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_train    = torch.stack( dataset_train )\n",
    "targets_train = torch.Tensor(  targets_train  ).type(   torch.LongTensor   )\n",
    "\n",
    "torch.save(   (data_train, targets_train, labels_train), \"InClass_CIFAR10_data\"     )\n",
    "\n",
    "## data1, targets1, labels1 = torch.load(\"InClass_CIFAR10_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 3, 32, 32])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "targets_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_train[4].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "targets_train[24000:25000]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Print images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.8392, 0.8353, 0.7059,  ..., 0.2471, 0.2902, 0.2627],\n",
       "         [0.8235, 0.8353, 0.7765,  ..., 0.1922, 0.2510, 0.2353],\n",
       "         [0.8118, 0.7961, 0.7922,  ..., 0.1882, 0.2471, 0.2431],\n",
       "         ...,\n",
       "         [0.2078, 0.1647, 0.1255,  ..., 0.4275, 0.4275, 0.4314],\n",
       "         [0.2392, 0.2471, 0.2235,  ..., 0.4235, 0.4392, 0.4588],\n",
       "         [0.2314, 0.2510, 0.2275,  ..., 0.4078, 0.4275, 0.4588]],\n",
       "\n",
       "        [[0.7529, 0.7490, 0.6196,  ..., 0.2588, 0.2980, 0.2706],\n",
       "         [0.7294, 0.7490, 0.6824,  ..., 0.2078, 0.2588, 0.2510],\n",
       "         [0.7059, 0.7020, 0.6863,  ..., 0.2196, 0.2627, 0.2706],\n",
       "         ...,\n",
       "         [0.2118, 0.1647, 0.1255,  ..., 0.4000, 0.4039, 0.4196],\n",
       "         [0.2353, 0.2392, 0.2157,  ..., 0.3961, 0.4157, 0.4353],\n",
       "         [0.2196, 0.2392, 0.2118,  ..., 0.3725, 0.4039, 0.4353]],\n",
       "\n",
       "        [[0.5569, 0.5569, 0.4353,  ..., 0.1922, 0.2471, 0.2275],\n",
       "         [0.5412, 0.5569, 0.5098,  ..., 0.1412, 0.2039, 0.1961],\n",
       "         [0.5294, 0.5216, 0.5176,  ..., 0.1373, 0.1961, 0.2000],\n",
       "         ...,\n",
       "         [0.1569, 0.1176, 0.0941,  ..., 0.3608, 0.3569, 0.3608],\n",
       "         [0.1647, 0.1804, 0.1686,  ..., 0.3569, 0.3686, 0.3804],\n",
       "         [0.1451, 0.1725, 0.1647,  ..., 0.3373, 0.3569, 0.3804]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "img_tr = data_train[46000]\n",
    "img_tr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform = T.ToPILImage()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img = transform(  img_tr  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDa1eCG5u5TMo3R5QnHOOxrzvVPCdxA8n2dwq7gAGPUdcj2rrtauYCrLaX5Qtz5kJ3HA7c/WuX0S/1GPX0ku9RuprZE3DeuVB9MHiuOhTb16G9acdjo9M0y9sNF8u9kAiuMeWucbRjoR2ya5TXXlV41JbCsVbsGPJB/ImvSriVzcaGbi1mja5l2zI/CqwPAI7ZAzWX460i1hgt2t7Yb5GOAzgKOKt0YwTmtzB3bsjj9I0+J9I8zUILszmRwJYmBAwccit3RvD1jeasiWeqXkYA3MsiYPH8688XWda03cttO3k7twRvmA5zx6Vt6L8TrvTfMN1pfnymRpFZH24J7dDx1rrhUcUkmRKnF9DofF9zPouqLFZtNeSwBZhLcP8iyAH5cfQ5rH0bVRr0L/wDCQSymJm3IIGC7GB7Z9iaqXerz+Ji17cpGHmPzRoDgdsfyqew09IUCosajP3QuKzqScrpmkI8uqP/Z",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Class balance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_train_np = targets_train.numpy() \n",
    "y_train_np.shape\n",
    "\n",
    "the_set = np.unique(  y_train_np  )\n",
    "the_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "_ = plt.hist( targets_train.numpy() , bins=\"auto\" )\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Test Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_test = []\n",
    "labels_test = []\n",
    "targets_test = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_132106/1136155179.py:7: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  img_arr = imageio.imread(  os.path.join(raw_data_test, folder, image), pilmode=\"RGB\"  )\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for folder in sorted( os.listdir( raw_data_test ) ):\n",
    "    ## print(folder)\n",
    "    for image in sorted( os.listdir( os.path.join(raw_data_test, folder) ) ):\n",
    "        if folder not in labels_test:\n",
    "            labels_test.append( folder )\n",
    "        targets_test.append(  labels_test.index(folder)  )\n",
    "        img_arr = imageio.imread(  os.path.join(raw_data_test, folder, image), pilmode=\"RGB\"  )\n",
    "        \n",
    "        img = torch.from_numpy( img_arr ).permute( 2, 0, 1 ).float()\n",
    "        \n",
    "        img /= 255\n",
    "        dataset_test.append(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_test   = torch.stack( dataset_test )\n",
    "targets_test = torch.Tensor(  targets_test  ).type(   torch.LongTensor   )\n",
    "\n",
    "torch.save(   (data_test, targets_test, labels_test), \"InClass_CIFAR10_data_test\"     )\n",
    "\n",
    "## data1, targets1, labels1 = torch.load(\"InClass_CIFAR10_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 3, 32, 32])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "targets_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAGdCAYAAAAMm0nCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAfCklEQVR4nO3de2xUdf7/8Vcv9CL2QjGdobFg1xihgnIp1AHXdaWhajUSG12y1WWVwMZtldIEpbtQtFwqXcUuUECMCxipt2zwwk9ZuyVLVUpbi7gILJjoTxrItG6wHamhQHt+f/jlfHcUVPxNd/qmz0dyEnvOZ868x6HhmcOZNsJxHEcAAACGRIZ7AAAAgAtFwAAAAHMIGAAAYA4BAwAAzCFgAACAOQQMAAAwh4ABAADmEDAAAMCc6HAP0Fd6e3t17NgxJSQkKCIiItzjAACAH8FxHH311VdKS0tTZOT5r7NctAFz7Ngxpaenh3sMAADwE7S2turyyy8/7/GLNmASEhIkffM/IDExMczTAACAHyMQCCg9Pd39e/x8LtqAOfvPRomJiQQMAADG/NDtH9zECwAAzCFgAACAOQQMAAAwh4ABAADmEDAAAMAcAgYAAJhDwAAAAHMIGAAAYA4BAwAAzCFgAACAORccMPX19brjjjuUlpamiIgIvfbaa0HHHcdRWVmZhg0bpvj4eOXk5OiTTz4JWnP8+HEVFBQoMTFRycnJmjVrlk6cOBG05p///Kd+/vOfKy4uTunp6aqsrLzwVwcAAC5KFxwwXV1duu6661RdXX3O45WVlVq1apXWr1+vxsZGDR48WLm5uTp58qS7pqCgQPv371dtba22bdum+vp6zZkzxz0eCAQ0bdo0jRgxQi0tLfrTn/6kxx57TBs2bPgJLxEAAFx0nP8PkpytW7e6X/f29jper9f505/+5O7r6OhwYmNjnRdffNFxHMc5cOCAI8lpbm5217z99ttORESEc/ToUcdxHGft2rXOkCFDnO7ubnfNo48+6lx99dU/erbOzk5HktPZ2flTXx4AAPgv+7F/f4f0HpjPPvtMfr9fOTk57r6kpCRlZ2eroaFBktTQ0KDk5GRlZWW5a3JychQZGanGxkZ3zY033qiYmBh3TW5urg4dOqQvv/zynM/d3d2tQCAQtAEAgItTdChP5vf7JUkejydov8fjcY/5/X6lpqYGDxEdrZSUlKA1GRkZ3znH2WNDhgz5znNXVFTo8ccfD80L+QFXLPg/fXbu//tEXp+c1+LMUt/NzczBLM7cVyx+r1icWbL5546Z/1e4v78vmk8hlZaWqrOz091aW1vDPRIAAOgjIQ0Yr9crSWprawva39bW5h7zer1qb28POn7mzBkdP348aM25zvGfz/FtsbGxSkxMDNoAAMDFKaQBk5GRIa/Xq7q6OndfIBBQY2OjfD6fJMnn86mjo0MtLS3umh07dqi3t1fZ2dnumvr6ep0+fdpdU1tbq6uvvvqc/3wEAAAGlgsOmBMnTmjv3r3au3evpG9u3N27d6+OHDmiiIgIFRcXa+nSpXrjjTe0b98+/eY3v1FaWpqmT58uSRo1apRuueUWzZ49W01NTXr//fdVVFSkGTNmKC0tTZL061//WjExMZo1a5b279+vl19+WX/+859VUlISshcOAADsuuCbeD/44AP98pe/dL8+GxUzZ87Upk2b9Mgjj6irq0tz5sxRR0eHbrjhBm3fvl1xcXHuY7Zs2aKioiJNnTpVkZGRys/P16pVq9zjSUlJeuedd1RYWKgJEybosssuU1lZWdDPigEAAAPXBQfMTTfdJMdxzns8IiJC5eXlKi8vP++alJQU1dTUfO/zXHvttXr33XcvdDwAADAAXDSfQgIAAAMHAQMAAMwhYAAAgDkEDAAAMIeAAQAA5hAwAADAHAIGAACYQ8AAAABzCBgAAGAOAQMAAMwhYAAAgDkEDAAAMIeAAQAA5hAwAADAHAIGAACYQ8AAAABzCBgAAGAOAQMAAMwhYAAAgDkEDAAAMIeAAQAA5hAwAADAHAIGAACYQ8AAAABzCBgAAGAOAQMAAMwhYAAAgDkEDAAAMIeAAQAA5hAwAADAHAIGAACYQ8AAAABzCBgAAGAOAQMAAMwhYAAAgDkEDAAAMIeAAQAA5hAwAADAHAIGAACYQ8AAAABzCBgAAGAOAQMAAMwhYAAAgDkEDAAAMIeAAQAA5hAwAADAHAIGAACYQ8AAAABzCBgAAGAOAQMAAMwhYAAAgDkEDAAAMIeAAQAA5hAwAADAHAIGAACYQ8AAAABzCBgAAGAOAQMAAMwhYAAAgDkEDAAAMCfkAdPT06NFixYpIyND8fHxuvLKK7VkyRI5juOucRxHZWVlGjZsmOLj45WTk6NPPvkk6DzHjx9XQUGBEhMTlZycrFmzZunEiROhHhcAABgU8oBZsWKF1q1bpzVr1ujgwYNasWKFKisrtXr1andNZWWlVq1apfXr16uxsVGDBw9Wbm6uTp486a4pKCjQ/v37VVtbq23btqm+vl5z5swJ9bgAAMCg6FCfcNeuXbrzzjuVl5cnSbriiiv04osvqqmpSdI3V1+qqqq0cOFC3XnnnZKk559/Xh6PR6+99ppmzJihgwcPavv27WpublZWVpYkafXq1brtttv05JNPKi0tLdRjAwAAQ0J+BWby5Mmqq6vT4cOHJUkfffSR3nvvPd16662SpM8++0x+v185OTnuY5KSkpSdna2GhgZJUkNDg5KTk914kaScnBxFRkaqsbHxnM/b3d2tQCAQtAEAgItTyK/ALFiwQIFAQCNHjlRUVJR6enq0bNkyFRQUSJL8fr8kyePxBD3O4/G4x/x+v1JTU4MHjY5WSkqKu+bbKioq9Pjjj4f65QAAgH4o5FdgXnnlFW3ZskU1NTXas2ePNm/erCeffFKbN28O9VMFKS0tVWdnp7u1trb26fMBAIDwCfkVmPnz52vBggWaMWOGJGnMmDH6/PPPVVFRoZkzZ8rr9UqS2traNGzYMPdxbW1tGjt2rCTJ6/Wqvb096LxnzpzR8ePH3cd/W2xsrGJjY0P9cgAAQD8U8iswX3/9tSIjg08bFRWl3t5eSVJGRoa8Xq/q6urc44FAQI2NjfL5fJIkn8+njo4OtbS0uGt27Nih3t5eZWdnh3pkAABgTMivwNxxxx1atmyZhg8frmuuuUYffvihVq5cqQceeECSFBERoeLiYi1dulRXXXWVMjIytGjRIqWlpWn69OmSpFGjRumWW27R7NmztX79ep0+fVpFRUWaMWMGn0ACAAChD5jVq1dr0aJF+v3vf6/29nalpaXpd7/7ncrKytw1jzzyiLq6ujRnzhx1dHTohhtu0Pbt2xUXF+eu2bJli4qKijR16lRFRkYqPz9fq1atCvW4AADAoJAHTEJCgqqqqlRVVXXeNRERESovL1d5efl516SkpKimpibU4wEAgIsAvwsJAACYQ8AAAABzCBgAAGAOAQMAAMwhYAAAgDkEDAAAMIeAAQAA5hAwAADAHAIGAACYQ8AAAABzCBgAAGAOAQMAAMwhYAAAgDkEDAAAMIeAAQAA5hAwAADAHAIGAACYQ8AAAABzCBgAAGAOAQMAAMwhYAAAgDkEDAAAMIeAAQAA5hAwAADAHAIGAACYQ8AAAABzCBgAAGAOAQMAAMwhYAAAgDkEDAAAMIeAAQAA5hAwAADAHAIGAACYQ8AAAABzCBgAAGAOAQMAAMwhYAAAgDkEDAAAMIeAAQAA5hAwAADAHAIGAACYQ8AAAABzCBgAAGAOAQMAAMwhYAAAgDkEDAAAMIeAAQAA5hAwAADAHAIGAACYQ8AAAABzCBgAAGAOAQMAAMwhYAAAgDkEDAAAMIeAAQAA5hAwAADAHAIGAACYQ8AAAABzCBgAAGBOnwTM0aNHde+992ro0KGKj4/XmDFj9MEHH7jHHcdRWVmZhg0bpvj4eOXk5OiTTz4JOsfx48dVUFCgxMREJScna9asWTpx4kRfjAsAAIwJecB8+eWXmjJligYNGqS3335bBw4c0FNPPaUhQ4a4ayorK7Vq1SqtX79ejY2NGjx4sHJzc3Xy5El3TUFBgfbv36/a2lpt27ZN9fX1mjNnTqjHBQAABkWH+oQrVqxQenq6Nm7c6O7LyMhw/9txHFVVVWnhwoW68847JUnPP/+8PB6PXnvtNc2YMUMHDx7U9u3b1dzcrKysLEnS6tWrddttt+nJJ59UWlpaqMcGAACGhPwKzBtvvKGsrCzdfffdSk1N1bhx4/Tss8+6xz/77DP5/X7l5OS4+5KSkpSdna2GhgZJUkNDg5KTk914kaScnBxFRkaqsbHxnM/b3d2tQCAQtAEAgItTyAPm008/1bp163TVVVfpb3/7mx588EE9/PDD2rx5syTJ7/dLkjweT9DjPB6Pe8zv9ys1NTXoeHR0tFJSUtw131ZRUaGkpCR3S09PD/VLAwAA/UTIA6a3t1fjx4/X8uXLNW7cOM2ZM0ezZ8/W+vXrQ/1UQUpLS9XZ2elura2tffp8AAAgfEIeMMOGDVNmZmbQvlGjRunIkSOSJK/XK0lqa2sLWtPW1uYe83q9am9vDzp+5swZHT9+3F3zbbGxsUpMTAzaAADAxSnkATNlyhQdOnQoaN/hw4c1YsQISd/c0Ov1elVXV+ceDwQCamxslM/nkyT5fD51dHSopaXFXbNjxw719vYqOzs71CMDAABjQv4ppHnz5mny5Mlavny57rnnHjU1NWnDhg3asGGDJCkiIkLFxcVaunSprrrqKmVkZGjRokVKS0vT9OnTJX1zxeaWW25x/+np9OnTKioq0owZM/gEEgAACH3ATJw4UVu3blVpaanKy8uVkZGhqqoqFRQUuGseeeQRdXV1ac6cOero6NANN9yg7du3Ky4uzl2zZcsWFRUVaerUqYqMjFR+fr5WrVoV6nEBAIBBIQ8YSbr99tt1++23n/d4RESEysvLVV5eft41KSkpqqmp6YvxAACAcfwuJAAAYA4BAwAAzCFgAACAOQQMAAAwh4ABAADmEDAAAMAcAgYAAJhDwAAAAHMIGAAAYA4BAwAAzCFgAACAOQQMAAAwh4ABAADmEDAAAMAcAgYAAJhDwAAAAHMIGAAAYA4BAwAAzCFgAACAOQQMAAAwh4ABAADmEDAAAMAcAgYAAJhDwAAAAHMIGAAAYA4BAwAAzCFgAACAOQQMAAAwh4ABAADmEDAAAMAcAgYAAJhDwAAAAHMIGAAAYA4BAwAAzCFgAACAOQQMAAAwh4ABAADmEDAAAMAcAgYAAJhDwAAAAHMIGAAAYA4BAwAAzCFgAACAOQQMAAAwh4ABAADmEDAAAMAcAgYAAJhDwAAAAHMIGAAAYA4BAwAAzCFgAACAOQQMAAAwh4ABAADmEDAAAMAcAgYAAJhDwAAAAHMIGAAAYA4BAwAAzCFgAACAOX0eME888YQiIiJUXFzs7jt58qQKCws1dOhQXXrppcrPz1dbW1vQ444cOaK8vDxdcsklSk1N1fz583XmzJm+HhcAABjQpwHT3NysZ555Rtdee23Q/nnz5unNN9/Uq6++qp07d+rYsWO666673OM9PT3Ky8vTqVOntGvXLm3evFmbNm1SWVlZX44LAACM6LOAOXHihAoKCvTss89qyJAh7v7Ozk4999xzWrlypW6++WZNmDBBGzdu1K5du7R7925J0jvvvKMDBw7ohRde0NixY3XrrbdqyZIlqq6u1qlTp/pqZAAAYESfBUxhYaHy8vKUk5MTtL+lpUWnT58O2j9y5EgNHz5cDQ0NkqSGhgaNGTNGHo/HXZObm6tAIKD9+/ef8/m6u7sVCASCNgAAcHGK7ouTvvTSS9qzZ4+am5u/c8zv9ysmJkbJyclB+z0ej/x+v7vmP+Pl7PGzx86loqJCjz/+eAimBwAA/V3Ir8C0trZq7ty52rJli+Li4kJ9+vMqLS1VZ2enu7W2tv7XnhsAAPx3hTxgWlpa1N7ervHjxys6OlrR0dHauXOnVq1apejoaHk8Hp06dUodHR1Bj2tra5PX65Ukeb3e73wq6ezXZ9d8W2xsrBITE4M2AABwcQp5wEydOlX79u3T3r173S0rK0sFBQXufw8aNEh1dXXuYw4dOqQjR47I5/NJknw+n/bt26f29nZ3TW1trRITE5WZmRnqkQEAgDEhvwcmISFBo0ePDto3ePBgDR061N0/a9YslZSUKCUlRYmJiXrooYfk8/l0/fXXS5KmTZumzMxM3XfffaqsrJTf79fChQtVWFio2NjYUI8MAACM6ZObeH/I008/rcjISOXn56u7u1u5ublau3atezwqKkrbtm3Tgw8+KJ/Pp8GDB2vmzJkqLy8Px7gAAKCf+a8EzD/+8Y+gr+Pi4lRdXa3q6urzPmbEiBF66623+ngyAABgEb8LCQAAmEPAAAAAcwgYAABgDgEDAADMIWAAAIA5BAwAADCHgAEAAOYQMAAAwBwCBgAAmEPAAAAAcwgYAABgDgEDAADMIWAAAIA5BAwAADCHgAEAAOYQMAAAwBwCBgAAmEPAAAAAcwgYAABgDgEDAADMIWAAAIA5BAwAADCHgAEAAOYQMAAAwBwCBgAAmEPAAAAAcwgYAABgDgEDAADMIWAAAIA5BAwAADCHgAEAAOYQMAAAwBwCBgAAmEPAAAAAcwgYAABgDgEDAADMIWAAAIA5BAwAADCHgAEAAOYQMAAAwBwCBgAAmEPAAAAAcwgYAABgDgEDAADMIWAAAIA5BAwAADCHgAEAAOYQMAAAwBwCBgAAmEPAAAAAcwgYAABgDgEDAADMIWAAAIA5BAwAADCHgAEAAOYQMAAAwBwCBgAAmEPAAAAAcwgYAABgDgEDAADMCXnAVFRUaOLEiUpISFBqaqqmT5+uQ4cOBa05efKkCgsLNXToUF166aXKz89XW1tb0JojR44oLy9Pl1xyiVJTUzV//nydOXMm1OMCAACDQh4wO3fuVGFhoXbv3q3a2lqdPn1a06ZNU1dXl7tm3rx5evPNN/Xqq69q586dOnbsmO666y73eE9Pj/Ly8nTq1Cnt2rVLmzdv1qZNm1RWVhbqcQEAgEHRoT7h9u3bg77etGmTUlNT1dLSohtvvFGdnZ167rnnVFNTo5tvvlmStHHjRo0aNUq7d+/W9ddfr3feeUcHDhzQ3//+d3k8Ho0dO1ZLlizRo48+qscee0wxMTGhHhsAABjS5/fAdHZ2SpJSUlIkSS0tLTp9+rRycnLcNSNHjtTw4cPV0NAgSWpoaNCYMWPk8XjcNbm5uQoEAtq/f/85n6e7u1uBQCBoAwAAF6c+DZje3l4VFxdrypQpGj16tCTJ7/crJiZGycnJQWs9Ho/8fr+75j/j5ezxs8fOpaKiQklJSe6Wnp4e4lcDAAD6iz4NmMLCQn388cd66aWX+vJpJEmlpaXq7Ox0t9bW1j5/TgAAEB4hvwfmrKKiIm3btk319fW6/PLL3f1er1enTp1SR0dH0FWYtrY2eb1ed01TU1PQ+c5+Sunsmm+LjY1VbGxsiF8FAADoj0J+BcZxHBUVFWnr1q3asWOHMjIygo5PmDBBgwYNUl1dnbvv0KFDOnLkiHw+nyTJ5/Np3759am9vd9fU1tYqMTFRmZmZoR4ZAAAYE/IrMIWFhaqpqdHrr7+uhIQE956VpKQkxcfHKykpSbNmzVJJSYlSUlKUmJiohx56SD6fT9dff70kadq0acrMzNR9992nyspK+f1+LVy4UIWFhVxlAQAAoQ+YdevWSZJuuummoP0bN27Ub3/7W0nS008/rcjISOXn56u7u1u5ublau3atuzYqKkrbtm3Tgw8+KJ/Pp8GDB2vmzJkqLy8P9bgAAMCgkAeM4zg/uCYuLk7V1dWqrq4+75oRI0borbfeCuVoAADgIsHvQgIAAOYQMAAAwBwCBgAAmEPAAAAAcwgYAABgDgEDAADMIWAAAIA5BAwAADCHgAEAAOYQMAAAwBwCBgAAmEPAAAAAcwgYAABgDgEDAADMIWAAAIA5BAwAADCHgAEAAOYQMAAAwBwCBgAAmEPAAAAAcwgYAABgDgEDAADMIWAAAIA5BAwAADCHgAEAAOYQMAAAwBwCBgAAmEPAAAAAcwgYAABgDgEDAADMIWAAAIA5BAwAADCHgAEAAOYQMAAAwBwCBgAAmEPAAAAAcwgYAABgDgEDAADMIWAAAIA5BAwAADCHgAEAAOYQMAAAwBwCBgAAmEPAAAAAcwgYAABgDgEDAADMIWAAAIA5BAwAADCHgAEAAOYQMAAAwBwCBgAAmEPAAAAAcwgYAABgDgEDAADMIWAAAIA5BAwAADCHgAEAAOYQMAAAwBwCBgAAmNOvA6a6ulpXXHGF4uLilJ2draampnCPBAAA+oF+GzAvv/yySkpKtHjxYu3Zs0fXXXedcnNz1d7eHu7RAABAmPXbgFm5cqVmz56t+++/X5mZmVq/fr0uueQS/eUvfwn3aAAAIMyiwz3AuZw6dUotLS0qLS1190VGRionJ0cNDQ3nfEx3d7e6u7vdrzs7OyVJgUAg5PP1dn8d8nOe1RfzSjZnlvpubmYOZnHmvmLxe8XizJLNP3fM/L/6auaz53Uc5/sXOv3Q0aNHHUnOrl27gvbPnz/fmTRp0jkfs3jxYkcSGxsbGxsb20Wwtba2fm8r9MsrMD9FaWmpSkpK3K97e3t1/PhxDR06VBERESF7nkAgoPT0dLW2tioxMTFk58VPx3vSv/B+9C+8H/0L78cPcxxHX331ldLS0r53Xb8MmMsuu0xRUVFqa2sL2t/W1iav13vOx8TGxio2NjZoX3Jycl+NqMTERP7w9TO8J/0L70f/wvvRv/B+fL+kpKQfXNMvb+KNiYnRhAkTVFdX5+7r7e1VXV2dfD5fGCcDAAD9Qb+8AiNJJSUlmjlzprKysjRp0iRVVVWpq6tL999/f7hHAwAAYdZvA+ZXv/qVvvjiC5WVlcnv92vs2LHavn27PB5PWOeKjY3V4sWLv/PPVQgf3pP+hfejf+H96F94P0InwnF+6HNKAAAA/Uu/vAcGAADg+xAwAADAHAIGAACYQ8AAAABzCJgLVF1drSuuuEJxcXHKzs5WU1NTuEcakCoqKjRx4kQlJCQoNTVV06dP16FDh8I9Fv7HE088oYiICBUXF4d7lAHt6NGjuvfeezV06FDFx8drzJgx+uCDD8I91oDU09OjRYsWKSMjQ/Hx8bryyiu1ZMmSH/59PzgvAuYCvPzyyyopKdHixYu1Z88eXXfddcrNzVV7e3u4Rxtwdu7cqcLCQu3evVu1tbU6ffq0pk2bpq6urnCPNuA1NzfrmWee0bXXXhvuUQa0L7/8UlOmTNGgQYP09ttv68CBA3rqqac0ZMiQcI82IK1YsULr1q3TmjVrdPDgQa1YsUKVlZVavXp1uEczi49RX4Ds7GxNnDhRa9askfTNTwdOT0/XQw89pAULFoR5uoHtiy++UGpqqnbu3Kkbb7wx3OMMWCdOnND48eO1du1aLV26VGPHjlVVVVW4xxqQFixYoPfff1/vvvtuuEeBpNtvv10ej0fPPfecuy8/P1/x8fF64YUXwjiZXVyB+ZFOnTqllpYW5eTkuPsiIyOVk5OjhoaGME4GSers7JQkpaSkhHmSga2wsFB5eXlB3ycIjzfeeENZWVm6++67lZqaqnHjxunZZ58N91gD1uTJk1VXV6fDhw9Lkj766CO99957uvXWW8M8mV399ifx9jf//ve/1dPT852fBOzxePSvf/0rTFNB+uZKWHFxsaZMmaLRo0eHe5wB66WXXtKePXvU3Nwc7lEg6dNPP9W6detUUlKiP/zhD2pubtbDDz+smJgYzZw5M9zjDTgLFixQIBDQyJEjFRUVpZ6eHi1btkwFBQXhHs0sAgbmFRYW6uOPP9Z7770X7lEGrNbWVs2dO1e1tbWKi4sL9zjQN2GflZWl5cuXS5LGjRunjz/+WOvXrydgwuCVV17Rli1bVFNTo2uuuUZ79+5VcXGx0tLSeD9+IgLmR7rssssUFRWltra2oP1tbW3yer1hmgpFRUXatm2b6uvrdfnll4d7nAGrpaVF7e3tGj9+vLuvp6dH9fX1WrNmjbq7uxUVFRXGCQeeYcOGKTMzM2jfqFGj9Ne//jVMEw1s8+fP14IFCzRjxgxJ0pgxY/T555+roqKCgPmJuAfmR4qJidGECRNUV1fn7uvt7VVdXZ18Pl8YJxuYHMdRUVGRtm7dqh07digjIyPcIw1oU6dO1b59+7R37153y8rKUkFBgfbu3Uu8hMGUKVO+86MFDh8+rBEjRoRpooHt66+/VmRk8F+5UVFR6u3tDdNE9nEF5gKUlJRo5syZysrK0qRJk1RVVaWuri7df//94R5twCksLFRNTY1ef/11JSQkyO/3S5KSkpIUHx8f5ukGnoSEhO/cfzR48GANHTqU+5LCZN68eZo8ebKWL1+ue+65R01NTdqwYYM2bNgQ7tEGpDvuuEPLli3T8OHDdc011+jDDz/UypUr9cADD4R7NLscXJDVq1c7w4cPd2JiYpxJkyY5u3fvDvdIA5Kkc24bN24M92j4H7/4xS+cuXPnhnuMAe3NN990Ro8e7cTGxjojR450NmzYEO6RBqxAIODMnTvXGT58uBMXF+f87Gc/c/74xz863d3d4R7NLH4ODAAAMId7YAAAgDkEDAAAMIeAAQAA5hAwAADAHAIGAACYQ8AAAABzCBgAAGAOAQMAAMwhYAAAgDkEDAAAMIeAAQAA5hAwAADAnP8HnIXIOOe9lp4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "_ = plt.hist( targets_test.numpy() , bins=\"auto\" )\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = data_train  \n",
    "y_train = targets_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_test = data_test  \n",
    "y_test = targets_test \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Change to float 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = X_train.numpy()\n",
    "X_test  = X_test.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = X_train.astype(  np.float32  )\n",
    "X_test  = X_test.astype(   np.float32  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = torch.from_numpy(X_train )\n",
    "X_test = torch.from_numpy( X_test  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_norm_mean = (0.5, 0.5, 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_norm_std = (0.5, 0.5, 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "other_normalization = transforms.Compose([\n",
    "                            ## transforms.ToTensor(),\n",
    "                            transforms.Normalize( img_norm_mean, img_norm_std )\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preprocess = transforms.Compose([\n",
    "                 transforms.Resize(256),\n",
    "                 transforms.CenterCrop(224),\n",
    "                 transforms.ToTensor()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = other_normalization( X_train )  \n",
    "\n",
    "X_test  = other_normalization( X_test ) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Print shapes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_train[30000].item()\n",
    "type(y_train[30000].item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_train[30000].item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0431, -0.0431, -0.0275,  ..., -0.0275, -0.0275, -0.0275],\n",
       "         [-0.0118, -0.0118,  0.0118,  ..., -0.0431, -0.0431, -0.0431],\n",
       "         [ 0.0510,  0.0510,  0.0667,  ..., -0.0353, -0.0353, -0.0353],\n",
       "         ...,\n",
       "         [ 0.6157,  0.6157,  0.6000,  ...,  0.0588, -0.0980, -0.2471],\n",
       "         [ 0.3882,  0.3255,  0.2863,  ...,  0.1765,  0.0431, -0.2314],\n",
       "         [ 0.1686,  0.1059,  0.1059,  ..., -0.1843, -0.1608, -0.0588]],\n",
       "\n",
       "        [[ 0.6392,  0.6392,  0.6235,  ...,  0.5922,  0.5922,  0.5922],\n",
       "         [ 0.6549,  0.6627,  0.6471,  ...,  0.5765,  0.5765,  0.5765],\n",
       "         [ 0.6941,  0.6941,  0.6784,  ...,  0.5843,  0.5843,  0.5843],\n",
       "         ...,\n",
       "         [ 0.6784,  0.6941,  0.6941,  ...,  0.2078,  0.0510, -0.0902],\n",
       "         [ 0.4902,  0.4275,  0.4039,  ...,  0.2706,  0.1373, -0.1294],\n",
       "         [ 0.2784,  0.2157,  0.2392,  ..., -0.1059, -0.0824,  0.0196]],\n",
       "\n",
       "        [[ 0.8745,  0.8745,  0.8588,  ...,  0.8353,  0.8353,  0.8353],\n",
       "         [ 0.8824,  0.8745,  0.8745,  ...,  0.8196,  0.8196,  0.8196],\n",
       "         [ 0.8824,  0.8667,  0.8588,  ...,  0.8275,  0.8275,  0.8275],\n",
       "         ...,\n",
       "         [ 0.4980,  0.5059,  0.5216,  ...,  0.0353, -0.1216, -0.2863],\n",
       "         [ 0.3490,  0.2863,  0.2549,  ...,  0.1608,  0.0275, -0.2627],\n",
       "         [ 0.1451,  0.0824,  0.0980,  ..., -0.1765, -0.1686, -0.0667]]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    " X_train[78]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " CIFAR_train_list = [  ( X_train[i],  y_train[i].item() )  for i in range( X_train.shape[0]   )  ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " CIFAR_test_list = [  ( X_test[i],  y_test[i].item() )  for i in range( X_test.shape[0]   )  ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 64  ## 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dl = torch.utils.data.DataLoader( CIFAR_train_list, batch_size=batch_size, shuffle=True  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_dl = torch.utils.data.DataLoader( CIFAR_test_list, batch_size=10000, shuffle=True  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Residual Networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3x3 convolution\n",
    "def conv3x3(in_channels, out_channels, stride=1):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, \n",
    "                     stride=stride, padding=1, bias=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Residual block\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(in_channels, out_channels, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(out_channels, out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# ResNet\n",
    "class MyResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=10):\n",
    "        super(MyResNet, self).__init__()\n",
    "        self.in_channels = 16\n",
    "        self.conv = conv3x3(3, 16)\n",
    "        self.bn = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self.make_layer(block, 16, layers[0])\n",
    "        self.layer2 = self.make_layer(block, 32, layers[1], 2)\n",
    "        self.layer3 = self.make_layer(block, 64, layers[2], 2)\n",
    "        self.avg_pool = nn.AvgPool2d(8)\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "\n",
    "    def make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if (stride != 1) or (self.in_channels != out_channels):\n",
    "            downsample = nn.Sequential(\n",
    "                conv3x3(self.in_channels, out_channels, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels))\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        self.in_channels = out_channels\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.bn(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.avg_pool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Architectures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3072"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "32*32*3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DL_3h_net(nn.Module):\n",
    "    ## init the class\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear( 32*32*3 , 200)\n",
    "        self.act1    = nn.ReLU()\n",
    "        \n",
    "        self.linear2 = nn.Linear(200 , 100)\n",
    "        self.act2   = nn.ReLU()\n",
    "        \n",
    "        self.linear3 = nn.Linear( 100 ,50)\n",
    "        self.act3    = nn.ReLU()\n",
    "        \n",
    "        self.linear4 = nn.Linear(50 , 10)\n",
    "        self.act4    = nn.Softmax(dim=1)\n",
    "        \n",
    "        ## self.norm    = nn.LayerNorm()\n",
    "        \n",
    "    ## perform inference\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x            = self.linear1(x)\n",
    "        x            = self.act1(x)\n",
    "        x            = self.linear2(x)\n",
    "        x            = self.act2(x)\n",
    "        x            = self.linear3(x)\n",
    "        x            = self.act3(x)\n",
    "      \n",
    "        x            = self.linear4(x)\n",
    "        y_pred       = self.act4(x)\n",
    "        \n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CNN_net(nn.Module):\n",
    "    ## init the class\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            \n",
    "            ## conv layer 1\n",
    "            nn.Conv2d(3, 16, kernel_size=5, stride=1, padding=1  ),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.MaxPool2d(2, 2), \n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            ## conv layer 2\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=1  ),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2, 2), \n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            ## conv layer 2\n",
    "            nn.Conv2d(32, 32, kernel_size=5, stride=1, padding=1  ),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2, 2), \n",
    "            nn.Dropout(0.2),\n",
    "              \n",
    "            ## FeedForward\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Linear( 128 , 512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Linear(512, 10),\n",
    "            nn.Softmax(dim=1)        ## nn.LogSoftmax()\n",
    "            \n",
    "        \n",
    "        )\n",
    "        \n",
    "    ## perform inference\n",
    "    def forward(self, x):\n",
    "        \n",
    "        y_pred = self.model( x  )\n",
    "       \n",
    "        \n",
    "        return y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class View(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super().__init__()\n",
    "        # self.shape = shape,\n",
    "        self.shape = shape\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x.view(*self.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "  \n",
    "class CNN_net_DH(nn.Module):\n",
    "    ## init the class\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3),\n",
    "            ## nn.Conv2d(32, 32, 3),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout(0.25),\n",
    "            \n",
    "            nn.Conv2d(32, 64, 3),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout(0.25),\n",
    "            \n",
    "            nn.Conv2d(64, 128, 3, padding=2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout(0.25),\n",
    "            \n",
    "            nn.Conv2d(128, 256, 3),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout(0.25),\n",
    "            \n",
    "            View((-1, 256)),\n",
    "            \n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            \n",
    "            nn.Linear(128, 64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            \n",
    "            nn.Linear(64, 10) # Output 10 classes\n",
    "            ## nn.Softmax(dim=1)        ## nn.LogSoftmax()\n",
    "        )\n",
    "        \n",
    "            \n",
    "     \n",
    "    ## perform inference\n",
    "    def forward(self, x):\n",
    "        \n",
    "        y_pred = self.model( x  )\n",
    "       \n",
    "        \n",
    "        return y_pred\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MLP_net(nn.Module):\n",
    "    ## init the class\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear( 32*32*3 ,20)\n",
    "        self.act1    = nn.LeakyReLU()\n",
    "        self.linear2 = nn.Linear(20 , 10)\n",
    "        self.act2    = nn.Softmax(dim=1)\n",
    "        \n",
    "        self.norm    = nn.LayerNorm()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "        \n",
    "    ## perform inference\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x            = self.linear1(x)\n",
    "        x            = self.act1(x)\n",
    "        x            = self.norm(x)\n",
    "        x            = self.dropout(x)\n",
    "        \n",
    "        x            = self.linear2(x)\n",
    "        y_pred       = self.act2(x)\n",
    "        \n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def training_loop( N_Epochs, model, loss_fn, opt ):\n",
    "    for epoch in range(N_Epochs):\n",
    "        for xb, yb in train_dl:\n",
    "            \n",
    "            ## xb = xb.view(  (16, -1 ) )\n",
    "            \n",
    "            xb = xb.to( torch_device )\n",
    "            yb = yb.to( torch_device )\n",
    "            \n",
    "            y_pred = model(xb)\n",
    "            \n",
    "            loss = loss_fn(y_pred, yb)\n",
    "            \n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        \n",
    "        if epoch % 5 == 0:\n",
    "            print(epoch, \"loss=\", loss)\n",
    "            new_PATH = PATH + str(epoch)\n",
    "            print( new_PATH )\n",
    "            torch.save(model, new_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## torch.save(model, PATH)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Core functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N_Epochs      = 100\n",
    "learning_rate = 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## model = MLP_net()\n",
    "## model =  DL_3h_net()\n",
    "\n",
    "## model = CNN_net()\n",
    "\n",
    "model = CNN_net_DH()\n",
    "model.to( torch_device )\n",
    "\n",
    "## model = MyResNet(ResidualBlock, [2, 2, 2]).to( torch_device )\n",
    "\n",
    "\n",
    "opt = torch.optim.Adam(  model.parameters(), lr=learning_rate, weight_decay=0.001 )\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss= tensor(1.6114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/scratch/scholar/rcalix/CNN_model_CIFAR100\n",
      "5 loss= tensor(0.6898, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/scratch/scholar/rcalix/CNN_model_CIFAR105\n",
      "10 loss= tensor(0.9841, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/scratch/scholar/rcalix/CNN_model_CIFAR1010\n",
      "15 loss= tensor(0.3971, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/scratch/scholar/rcalix/CNN_model_CIFAR1015\n",
      "20 loss= tensor(0.9319, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/scratch/scholar/rcalix/CNN_model_CIFAR1020\n",
      "25 loss= tensor(0.5255, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/scratch/scholar/rcalix/CNN_model_CIFAR1025\n",
      "30 loss= tensor(1.1482, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/scratch/scholar/rcalix/CNN_model_CIFAR1030\n",
      "35 loss= tensor(0.9816, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/scratch/scholar/rcalix/CNN_model_CIFAR1035\n",
      "40 loss= tensor(1.0182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/scratch/scholar/rcalix/CNN_model_CIFAR1040\n",
      "45 loss= tensor(0.6801, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/scratch/scholar/rcalix/CNN_model_CIFAR1045\n",
      "50 loss= tensor(1.1481, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/scratch/scholar/rcalix/CNN_model_CIFAR1050\n",
      "55 loss= tensor(0.5008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/scratch/scholar/rcalix/CNN_model_CIFAR1055\n",
      "60 loss= tensor(0.8276, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/scratch/scholar/rcalix/CNN_model_CIFAR1060\n",
      "65 loss= tensor(0.5745, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/scratch/scholar/rcalix/CNN_model_CIFAR1065\n",
      "70 loss= tensor(1.1889, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/scratch/scholar/rcalix/CNN_model_CIFAR1070\n",
      "75 loss= tensor(0.6955, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/scratch/scholar/rcalix/CNN_model_CIFAR1075\n",
      "80 loss= tensor(1.0978, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/scratch/scholar/rcalix/CNN_model_CIFAR1080\n",
      "85 loss= tensor(0.9126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/scratch/scholar/rcalix/CNN_model_CIFAR1085\n",
      "90 loss= tensor(0.6823, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/scratch/scholar/rcalix/CNN_model_CIFAR1090\n",
      "95 loss= tensor(0.9822, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/scratch/scholar/rcalix/CNN_model_CIFAR1095\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_loop( N_Epochs, model, loss_fn, opt )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_metrics_function(y_test, y_pred):\n",
    "    print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))\n",
    "    confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confmat)\n",
    "    print('Precision: %.3f' % precision_score(y_true=y_test, y_pred=y_pred, average='weighted'))\n",
    "    print('Recall: %.3f' % recall_score(y_true=y_test, y_pred=y_pred, average='weighted'))\n",
    "    print('F1-measure: %.3f' % f1_score(y_true=y_test, y_pred=y_pred, average='weighted'))\n",
    "\n",
    "def testing_loop(test_dl, model, device):\n",
    "    my_f1 = 0.0\n",
    "    count = 0.0\n",
    "    with torch.no_grad():\n",
    "        for x_raw, y_raw in test_dl:\n",
    "            x_true, y_true = x_raw.to(device), y_raw.to(device)\n",
    "            _, y_pred = torch.max(model(x_true), dim=1)\n",
    "            my_f1 += f1_score(y_true, y_pred, num_classes=10)\n",
    "            count += 1\n",
    "    return my_f1 / count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for x_real, y_real in test_dl:\n",
    "        \n",
    "        batch_size = x_real.shape[0]\n",
    "        \n",
    "        ## x_real = x_real.view(  (batch_size, -1 ) )\n",
    "        \n",
    "        x_real = x_real.to( torch_device )\n",
    "        \n",
    "        y_pred = model(  x_real  )\n",
    "        \n",
    "        vals, indeces = torch.max( y_pred, dim=1  )\n",
    "        preds = indeces\n",
    "        print_metrics_function( y_real, preds.cpu() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7079, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(testing_loop(test_dl, model, torch_device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## From checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model class must be defined somewhere\n",
    "model2 = torch.load('/scratch/scholar/rcalix/CNN_model_CIFAR1095')\n",
    "## model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    for x_real, y_real in test_dl:\n",
    "        \n",
    "        batch_size = x_real.shape[0]\n",
    "        \n",
    "        ## x_real = x_real.view(  (batch_size, -1 ) )\n",
    "        \n",
    "        x_real = x_real.to( torch_device )\n",
    "        \n",
    "        y_pred = model2(  x_real  )\n",
    "        \n",
    "        vals, indeces = torch.max( y_pred, dim=1  )\n",
    "        preds = indeces\n",
    "        print_metrics_function(y_real, preds.cpu() )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rc = data_train[4].view((-1))\n",
    "rc.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rc = torch.unsqueeze(rc, dim=0)\n",
    "rc.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## example_label = model( rc )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## example_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Figure out the dimensions of CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N_batches_rc = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "model_rc = nn.Sequential(\n",
    "            \n",
    "            ## conv layer 1\n",
    "            nn.Conv2d(3, 16, kernel_size=5, stride=1, padding=1  ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), \n",
    "            \n",
    "            ## conv layer 2\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=1  ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), \n",
    "              \n",
    "            ## FeedForward\n",
    "            \n",
    "            nn.Flatten()\n",
    "            \n",
    "            \n",
    "        \n",
    "        )\n",
    "        \n",
    "'''\n",
    "\n",
    "\n",
    "model_rc  = nn.Sequential(\n",
    "            \n",
    "            ## conv layer 1\n",
    "            nn.Conv2d(3, 16, kernel_size=5, stride=1, padding=1  ),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.MaxPool2d(2, 2), \n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            ## conv layer 2\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=1  ),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2, 2), \n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            ## conv layer 3\n",
    "            nn.Conv2d(32, 32, kernel_size=5, stride=1, padding=1  ),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2, 2), \n",
    "            nn.Dropout(0.2),\n",
    "              \n",
    "            ## FeedForward\n",
    "            \n",
    "            nn.Flatten()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "my_tensor_test   = torch.randn(N_batches_rc, 3, 32,  32)\n",
    "\n",
    "res_actual_model = model_rc(  my_tensor_test   )\n",
    "\n",
    "res_actual_model.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "our_prefix",
   "language": "python",
   "name": "our_prefix"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
