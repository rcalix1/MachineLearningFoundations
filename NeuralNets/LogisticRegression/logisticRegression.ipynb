{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n",
      "(569,)\n",
      "accuracy  0.9473684210526315\n",
      "[1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 1 1 1 0 1 1\n",
      " 1 1 0]\n",
      "[1 1 0 1 0 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 1 1 1 0 1 1\n",
      " 1 1 0]\n",
      "<<<<<<<<<<<<DONE>>>>>>>>>>>>>\n"
     ]
    }
   ],
   "source": [
    "## simple binary log reg \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#######################################\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    accuracy = np.sum( y_true == y_pred ) / len(y_true)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "#######################################\n",
    "\n",
    "def mySigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "#######################################\n",
    "\n",
    "def predict(X, weights, bias):\n",
    "    z = np.dot( X, weights ) + bias\n",
    "    y_predicted = mySigmoid(z)\n",
    "    y_pred = [  1 if i > 0.5 else 0 for i in y_predicted  ]\n",
    "    return np.array(   y_pred   )\n",
    " \n",
    "#######################################\n",
    "\n",
    "def fit(X, y):\n",
    "    lr = 0.0001\n",
    "    n_iters = 1000\n",
    "    n_samples, n_features = X.shape  \n",
    "    \n",
    "    weights = np.zeros(n_features)\n",
    "    bias = 0\n",
    "    \n",
    "    # gradient descent\n",
    "    for _ in range(n_iters):\n",
    "        z = np.dot(   X, weights   ) + bias\n",
    "        y_pred = mySigmoid(z)\n",
    "        \n",
    "        ## compute gradients\n",
    "        ## derivatives of cross entropy\n",
    "        dw = (1 / n_samples) * np.dot(  X.T, (y_pred - y)  )\n",
    "        db = (1 / n_samples) * np.sum(  y_pred - y  )\n",
    "        \n",
    "        ## update parameters using the gradients\n",
    "        weights = weights - lr * dw\n",
    "        bias    = bias - lr * db\n",
    "        \n",
    "    return weights, bias\n",
    "\n",
    "\n",
    "#######################################\n",
    "\n",
    "bc = datasets.load_breast_cancer() \n",
    "X, y = bc.data, bc.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "#######################################\n",
    "\n",
    "print(X.shape) \n",
    "print(y.shape)\n",
    "\n",
    "#######################################\n",
    "\n",
    "#fig = plt.figure(figsize=(8, 6))\n",
    "#plt.scatter(X[:, 0], y, color = 'b', marker = 'o', s = 30)\n",
    "#plt.show()\n",
    "\n",
    "######################################\n",
    "\n",
    "\n",
    "weights, bias  = fit(X_train, y_train)\n",
    "y_pred = predict(X_test, weights, bias)\n",
    "\n",
    "accu_r = accuracy(y_pred, y_test)\n",
    "print(\"accuracy \", accu_r)\n",
    "\n",
    "print(y_pred[:40])\n",
    "print(y_test[:40])\n",
    "\n",
    "#####################################\n",
    "\n",
    "print(\"<<<<<<<<<<<<DONE>>>>>>>>>>>>>\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
